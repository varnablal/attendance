# import the libraries
	import os
	import face_recognition
	import cv2
	# make a list of all the available images
	#images = os.listdir(os.path.join(os.getcwd(),'Facelive\images'))
	ta=os.getcwd()
	images = os.listdir(os.path.join(ta,'camera/images'))
	images111 = os.path.join(ta,'camera/images')
	print(images111)
	font = cv2.FONT_HERSHEY_DUPLEX
	bottomLeftCornerOfText = (10, 400)
	fontScale = .5
	fontColor = (0, 0, 255)
	lineType = 1

	myPath = 'Facelive'
	print('Creating the haar cascade...')
	cascPath = os.path.join(myPath, 'haarcascades', 'haarcascade_frontalface_default.xml')
	faceCascade = cv2.CascadeClassifier(cascPath)
	attendance=[]
	def most_frequent(List): 
		counter = 0
		num = List[0] 
		
		for i in List: 
			curr_frequency = List.count(i) 
			if(curr_frequency> counter): 
				counter = curr_frequency 
				num = i 
	
		return num 
	
	List = [2, 1, 2, 2, 1, 3] 
	print(most_frequent(List)) 
	def current_minute():
		import time
		t = time.localtime()
		current_time = time.strftime("%H:%M:%S", t)
		data = current_time.split(':')
		return data[1]

	res1 = current_minute()
	print('Setting up camera...')
	cam = cv2.VideoCapture(0)
	lii=[]
	while True:
		res = current_minute()
		ret,frame = cam.read()

		k = cv2.waitKey(1)
		if k % 256 == 27:
			# ESC pressed
			print("Escape hit, closing...")
			break
		# load the example image and convert it to grayscale
		image = frame
		gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
		
		# Detect faces in the image
		faces = faceCascade.detectMultiScale(
			gray,
			scaleFactor=1.1,
			minNeighbors=5,
			minSize=(30, 30),
			flags=cv2.CASCADE_SCALE_IMAGE)
		#     There is only 1 driver. So consider only 1 detection

		if len(faces) == 0:
			continue
		
		face = [faces[0]]    
		# Draw a rectangle around the faces
		for (x1, y1, w, h) in face:
			cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 255, 0), 2)
			sub_face = frame[y1:y1+h, x1:x1+w]
		cv2.imshow('Webcam',frame)        


		filename = "{}.jpg".format(os.getpid())
		cv2.imwrite(filename, sub_face)


		image_to_be_matched = face_recognition.load_image_file(filename)

		try:
			# encoded the loaded image into a feature vector
			img_encoded = face_recognition.face_encodings(image_to_be_matched)[0]
		except IndexError:
			continue
		
		# iterate over each image
		for image in images:
			# load the image
			current_image = face_recognition.load_image_file(images111 +'/'+ image)
			# encode the loaded image into a feature vector
			current_image_encoded = face_recognition.face_encodings(current_image)[0]
			# match your image with the image and check if it matches
			result = face_recognition.compare_faces(
				[img_encoded], current_image_encoded)
			
			# check if it was a match
			if result[0] == True:
				im = image[:-4]
				im = im.upper()
				
				lii.append(im)
			# print(lii)
				if len(lii)>10:
					attendance.append(most_frequent(lii))
					lii=[]
			print(res)        
				
			if int(res)==int(res1)+1:
				
				cam.release()
				cv2.destroyAllWindows()
				return attendance
				attendance=[]
				cam.release()
				cv2.destroyAllWindows()
				exit()
				
					

					
				
			#else:
				#print("Not matched: ",image)
	# When everything done, release the capture
	#cap.release()
	cv2.destroyAllWindows()
	#Returns the captured image's name
	print('Saved.')

